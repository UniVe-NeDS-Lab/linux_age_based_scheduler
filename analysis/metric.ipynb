{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import orjson\n",
    "import pandas as pd\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "plt.rcParams['figure.figsize'] = [14, 9]\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = utils.load_log_df([\n",
    "    '../logs/long2/*.json.gz',\n",
    "])\n",
    "logs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_algos = ['cake', 'cakeage']\n",
    "algorithm_renames = {\n",
    "    'age': 'age-prio-codel',\n",
    "    'pfifofast': 'age-pfifofast',\n",
    "    'cakeage': 'age-cake',\n",
    "}\n",
    "setup_renames = {\n",
    "    'long2': '12 hours, 5 classes',\n",
    "}\n",
    "\n",
    "# logs['algorithm'] = logs['algorithm'].cat.reorder_categories([*logs['algorithm'].cat.categories.difference(append_algos), *append_algos])\n",
    "logs['algorithm'] = logs['algorithm'].cat.rename_categories(lambda x: algorithm_renames.get(x, x))\n",
    "logs['algorithm'] = logs['algorithm'].cat.reorder_categories(['age-cake', 'age-pfifofast', 'age-prio-codel', 'cake', 'codel', 'fqcodel', 'pfifo'])\n",
    "logs['setup'] = logs['setup'].apply(lambda x: setup_renames.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs =  mpl.color_sequences['tab20']\n",
    "color = [cs[0], cs[2], cs[4], cs[6], cs[1], cs[5], cs[7], cs[3]]\n",
    "\n",
    "def time_bar_plot(data: pd.DataFrame, **kwargs):\n",
    "    data = data.agg(mean_time=('time', 'mean'), sem_time=('time', 'sem'))\n",
    "    data['interval'] = data['sem_time'] * 1.96 # 95% confidence interval\n",
    "    data.unstack().plot(kind='bar', y='mean_time', yerr='interval', rot=kwargs.pop('rot', 0), ylabel='time (s)', color=color, **kwargs)\n",
    "\n",
    "def cumulative_traffic_plot(data: pd.DataFrame, **kwargs):\n",
    "    data = data.groupby(['size']).agg(total_data=('size', 'sum')).cumsum()\n",
    "    data.plot(kind='line', y='total_data', ylabel='total data (bytes)', rot=kwargs.pop('rot', 0), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logsa = utils.load_antler_df('../tests/results/6h-*/*.json')\n",
    "logsa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(14, 6))\n",
    "cumulative_traffic_plot(logs, ax=ax0, title='5 classes')\n",
    "cumulative_traffic_plot(logsa, ax=ax1, title='continuous pareto alpha=1.2 bounded 300Ki-1Gi')\n",
    "plt.legend(loc='lower right')\n",
    "for ax in [ax0, ax1]:\n",
    "    ax.set_ylim(0, None)\n",
    "    ax.axvline(55*1024**2, color='red', linestyle='--')\n",
    "fig.suptitle('Total traffic of flows shorter than x bytes')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "df = logs.groupby(['setup', 'algorithm'], observed=True).agg(total_data=('size', 'sum'), n_exps=('date', 'nunique'))\n",
    "df['total_data'] = df['total_data'] / df['n_exps'] / (1_000_000_000 / 8 * 12 * 3600)\n",
    "df.unstack().plot(kind='bar', y='total_data', rot=0, ax=ax0, color=color)\n",
    "ax0.set_title('5 classes')\n",
    "ax0.axhline(1, linestyle='-')\n",
    "ax0.axhline(0.7, linestyle='--')\n",
    "\n",
    "df = logsa.groupby(['date', 'algorithm'], observed=True).agg(total_data=('size', 'sum'), n_exps=('date', 'nunique'))\n",
    "df['total_data'] = df['total_data'] / df['n_exps'] / (1_000_000_000 / 8 * 6 * 3600)\n",
    "df.unstack().plot(kind='bar', y='total_data', rot=0, ax=ax1, color=color)\n",
    "ax1.set_title('continuous pareto alpha=1.2 bounded 300Ki-1Gi')\n",
    "ax1.axhline(1, linestyle='-')\n",
    "ax1.axhline(0.7, linestyle='--')\n",
    "\n",
    "fig.suptitle('Goodput divided by the link capacity of 1 Gbps')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(3,2, sharex=False)\n",
    "# legend = False\n",
    "# for ((size, group), ax) in zip(logsa[goodflows].groupby('size', observed=False), axes.flatten()):\n",
    "#     time_bar_plot(group.groupby(['setup', 'algorithm'], observed=False), ax=ax)\n",
    "#     ax.set_title(f'size={utils.prettyprint_bytes(size)}')\n",
    "#     ax.get_legend().remove()\n",
    "#     if not legend:\n",
    "#         fig.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "#         legend = True\n",
    "# fig.suptitle('Mean completion time per connection')\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = logs[(logs['start_at'] > 3600)]\n",
    "# dfa = logsa[(logsa['start_at'] > 20) & (logsa['start_at'] < 1800 - 20)]\n",
    "\n",
    "# fig, (ax0, ax1) = plt.subplots(1,2, sharex=False, sharey=True)\n",
    "# # time_bar_plot(df.groupby(['date', 'algorithm']), ax=ax0)\n",
    "# time_bar_plot(dfa.groupby(['date', 'algorithm']), ax=ax1)\n",
    "# ax0.set_title('python+iperf2 generator, 12h')\n",
    "# ax1.set_title('antler generator, 30m')\n",
    "# ax0.legend(loc='lower left')\n",
    "# ax1.legend(loc='lower left')\n",
    "# fig.suptitle('Mean completion time per connection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "df = logs[(logs['start_at'] > 3600) & (logs['start_at'] + logs['time'] < 12*3600 - 60)]\n",
    "time_bar_plot(df.groupby(['setup', 'algorithm']), ax=ax0)\n",
    "ax0.set_title('5 classes')\n",
    "ax0.legend(loc='lower left')\n",
    "\n",
    "df = logsa[(logsa['start_at'] > 3600) & (logsa['start_at'] + logsa['time'] < 6*3600 - 60)]\n",
    "time_bar_plot(df.groupby(['date', 'algorithm']), ax=ax1)\n",
    "ax1.set_title('continuous pareto alpha=1.2 bounded 300Ki-1Gi')\n",
    "ax1.legend(loc='lower left')\n",
    "\n",
    "fig.suptitle('Mean completion time per connection')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logsa\n",
    "bins = [0, 1_000_000, 10_000_000, 55000000, 100_000_000, 800_000_000, np.inf]\n",
    "labels = ['<1M', '1M-10M', '10M-55M', \"55M-100M\", '100M-800M', '>800M']\n",
    "df['size_cat'] = pd.cut(df['size'], bins=bins, labels=labels)\n",
    "\n",
    "logsa.groupby(['date', 'algorithm', 'size_cat'], observed=True).agg(total_flows=('date', 'count')).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logs.groupby(['date', 'size']).agg(mean_time=('time', 'mean'))\n",
    "logs.groupby(['setup', 'seed', 'algorithm', 'size'], observed=True).agg(total_flows=('date', 'count')).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs[(logs['setup'] == setup_renames['long2']) & (logs['seed'] == '15867')]\n",
    "df = logsa[logsa['date'] == '6h-pareto1.2-heavy']\n",
    "df['ended_at'] = df['start_at'] + df['time']\n",
    "timepoints = np.linspace(0, df['ended_at'].max(), 200)\n",
    "algos = df['algorithm'].cat.categories\n",
    "partial_means = np.zeros((0, len(algos)))\n",
    "partial_sems = np.zeros((0, len(algos)))\n",
    "\n",
    "fig, ax = plt.subplots(sharey=True)\n",
    "\n",
    "for t in timepoints:\n",
    "    c = df[(df['ended_at'] <= t) & (df['ended_at'] > 3600) & (df['ended_at'] < 6*3600 - 20)]\n",
    "    c = c.groupby('algorithm', observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem'))\n",
    "    partial_means = np.vstack([partial_means, c.loc[algos, 'mean_time']])\n",
    "    partial_sems = np.vstack([partial_sems, c.loc[algos, 'sem_time']])\n",
    "\n",
    "for i, a in enumerate(algos):\n",
    "    ax.plot(timepoints, partial_means[:, i], label=a, color=color[i])\n",
    "    ax.fill_between(timepoints, partial_means[:, i] - 1.96 * partial_sems[:, i], partial_means[:, i] + 1.96 * partial_sems[:, i], alpha=0.3, color=color[i])\n",
    "    ax.axhline(partial_means[-1, i], linestyle='--', color=color[i], alpha=0.5)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylabel('mean completion time (s)')\n",
    "ax.set_xlabel('elapsed time (s)')\n",
    "ax.set_title('Expanding mean completion time per connection, for runs with the same seed')\n",
    "fig.tight_layout()\n",
    "# df.sort_values('start_at').groupby('algorithm', observed=True)['start_at', 'time'].expanding().mean().unstack().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, sharex=True, figsize=(14, 12))\n",
    "\n",
    "# for algo, ax in zip(['age+prio+codel', 'cake'], axs):\n",
    "#     df = logs[(logs['setup'] == setup_renames['long2']) & (logs['algorithm'] == algo)]\n",
    "#     df['ended_at'] = df['start_at'] + df['time']\n",
    "#     timepoints = np.linspace(0, df['ended_at'].max(), 200)\n",
    "#     partial_means = np.zeros((0, 3))\n",
    "#     partial_sems = np.zeros((0, 3))\n",
    "#     seeds = df['seed'].unique()\n",
    "\n",
    "\n",
    "#     for t in timepoints:\n",
    "#         c = df[(df['ended_at'] <= t) & (df['ended_at'] > 3600)].groupby('seed', observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem'))\n",
    "#         partial_means = np.vstack([partial_means, c.loc[seeds, 'mean_time']])\n",
    "#         partial_sems = np.vstack([partial_sems, c.loc[seeds, 'sem_time']])\n",
    "\n",
    "#     for i, a in enumerate(seeds):\n",
    "#         ax.plot(timepoints, partial_means[:, i], label=a)\n",
    "#         ax.fill_between(timepoints, partial_means[:, i] - 1.96 * partial_sems[:, i], partial_means[:, i] + 1.96 * partial_sems[:, i], alpha=0.3, label=f'{a} 95% CI')\n",
    "#         ax.axhline(partial_means[-1, i], linestyle='--', color=f'C{i}', alpha=0.5)\n",
    "#     ax.legend()\n",
    "#     ax.set_ylabel('mean completion time (s)')\n",
    "#     ax.set_xlabel('elapsed time (s)')\n",
    "#     ax.set_title(algo)\n",
    "\n",
    "# fig.suptitle('Expanding mean completion time per connection')\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_bins = np.linspace(0, 60, 150)\n",
    "\n",
    "# for d in [logs['date'].cat.categories[-2], logs['date'].cat.categories[-1]]:\n",
    "#     df = logs[(logs['date'] == d) & logs['algorithm'].isin(['age+prio+codel', 'cake'])]\n",
    "\n",
    "#     for algorithm, df_group in df.groupby('algorithm', observed=True):\n",
    "#         df_group['start_at'] = df_group['start_at'] - df_group['start_at'].min()\n",
    "#         df_group['end_at'] = df_group['start_at'] + df_group['time']\n",
    "\n",
    "#         active_counts = pd.DataFrame(index=time_bins, columns=df_group['size'].unique()).fillna(0).infer_objects(copy=False)\n",
    "\n",
    "#         for time in time_bins:\n",
    "#             active_at_t = df_group[(df_group['start_at'] <= time) & (df_group['end_at'] > time)]  # Instances active at `time`\n",
    "#             counts = active_at_t['size'].value_counts()  # Count per size\n",
    "#             active_counts.loc[time, counts.index] = counts.values  # Store in DataFrame\n",
    "\n",
    "#         active_counts = active_counts.fillna(0)\n",
    "#         active_counts = active_counts[active_counts.columns.sort_values()]\n",
    "#         active_counts.columns = active_counts.columns.map(utils.prettyprint_bytes)  \n",
    "#         active_counts.plot(kind='area', stacked=True)\n",
    "\n",
    "#         plt.title(f'Active instances over time ({algorithm}), date: {d}')\n",
    "#         plt.xlabel('time from experiment start (s)')\n",
    "#         plt.ylabel('active connections')\n",
    "#         plt.ylim(0, 30)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
