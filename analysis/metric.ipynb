{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "import numpy as np\n",
    "import orjson\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "plt.rcParams['figure.figsize'] = [14, 9]\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs1g = utils.load_antler_df(\n",
    "    # '../tests/results/1gbps/*/*_streams.json*',\n",
    "    '../tests/results/1gbps/*/*_codel_streams.json*',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs10g = utils.load_antler_df(\n",
    "    # '../tests/results/10gbps/*-2/*_streams.json*',\n",
    "    # '../tests/results/10gbps/*-3/*_streams.json*',\n",
    "    # '../tests/results/10gbps/dead/*_streams.json*',\n",
    "    # '../tests/results/10gbps/newpie1/*pie_streams.json*',\n",
    "    # '../tests/results/10gbps/newpie3/*pie_streams.json*',\n",
    "    '../tests/results/10gbps/4h-10g-*/*_codel_streams.json*',\n",
    "    # '../tests/results/10gbps/4h-10g-*/*fifo*_streams.json*',\n",
    "    # '../tests/results/10gbps/4h-10g-*/*cake_streams.json*',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_order = [\n",
    "    'age-pfifofast',\n",
    "    'pfifo',\n",
    "    'age-cake',\n",
    "    'cake',\n",
    "    'age-prio-fqcodel',\n",
    "    'fqcodel',\n",
    "    'age-prio-codel',\n",
    "    'codel',\n",
    "    'age-prio-fqpie',\n",
    "    'fqpie',\n",
    "    'age-prio-pie',\n",
    "    'pie',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs1g['algorithm'] = logs1g['algorithm'].cat.set_categories(algo_order)\n",
    "# logs1g['date'] = (\n",
    "#     logs1g['date']\n",
    "#     .cat.rename_categories(\n",
    "#         {\n",
    "#             # '6h-pareto1.2-heavy2-fixed': 'threshold 86MiB',\n",
    "#             '6h-pareto1.2-heavy3': 'seed=325 thr=6MiB (phfit+toolkit)',\n",
    "#             '6h-pareto1.2-heavy4': 'seed=325 thr=13MiB (kneed)',\n",
    "#             '6h-pareto1.2-heavy5': 'seed=326 thr=6MiB (phfit+toolkit)',\n",
    "#         }\n",
    "#     )\n",
    "#     .cat.reorder_categories(\n",
    "#         [\n",
    "#             'seed=325 thr=6MiB (phfit+toolkit)',\n",
    "#             'seed=325 thr=13MiB (kneed)',\n",
    "#             'seed=326 thr=6MiB (phfit+toolkit)',\n",
    "#         ]\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs10g['algorithm'] = logs10g['algorithm'].cat.set_categories(algo_order, ordered=True)\n",
    "# logs10g['date'] = (\n",
    "#     logs10g['date']\n",
    "#     .cat.rename_categories(\n",
    "#         {\n",
    "#             # '2025-04-19-162850Z': '2h, medium load',\n",
    "#             # '2025-04-22-071430Z': '1h, heavy load',\n",
    "#             # '4h-10g-1': '4h',\n",
    "#             '4h-10g-2': 'thr=19MiB (phfit+toolkit)',\n",
    "#             '4h': 'thr=19MiB (phfit+toolkit)',\n",
    "#         }\n",
    "#     )\n",
    "#     # .cat.reorder_categories(\n",
    "#     #     [\n",
    "#     #         '4h',\n",
    "#     #     ]\n",
    "#     # )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "cs =  mpl.color_sequences['tab20']\n",
    "color = cs # [cs[0], cs[2], cs[4], cs[6], cs[1], cs[5], cs[7], cs[3]]\n",
    "\n",
    "def time_bar_plot(data: pd.DataFrame, **kwargs):\n",
    "    data = data.agg(mean_time=('time', 'mean'), sem_time=('time', 'sem'))\n",
    "    data['interval'] = data['sem_time'] * 1.96 # 95% confidence interval\n",
    "    ax = data.unstack().plot(kind='bar', y='mean_time', yerr='interval', rot=kwargs.pop('rot', 0), ylabel='time (s)', color=color, **kwargs)\n",
    "    data = [c.datavalues for c in ax.containers if isinstance(c, mpl.container.BarContainer)]\n",
    "    data = zip(data[0::2], data[1::2])\n",
    "    data = list(itertools.chain.from_iterable((d/e-1, [None]*len(e)) for d, e in data))\n",
    "    for i, container in enumerate(filter(lambda x: isinstance(x, mpl.container.BarContainer), ax.containers)):\n",
    "        ann = ax.bar_label(container, label_type='edge', fontsize=8, padding=3)\n",
    "        for j, label in enumerate(ann):\n",
    "            label.set_text(f\"{data[i][j]:.1%}\" if data[i][j] else '')\n",
    "\n",
    "def cumulative_traffic_plot(data: pd.DataFrame, **kwargs):\n",
    "    data = data.groupby(['size']).agg(total_data=('size', 'sum')).cumsum()\n",
    "    data.plot(kind='line', y='total_data', ylabel='total data (bytes)', rot=kwargs.pop('rot', 0), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(15, 6), sharey=True, width_ratios=(2,1))\n",
    "\n",
    "# df = logs1g.groupby(['date', 'algorithm'], observed=False).agg(total_data=('size', 'sum'), n_exps=('date', 'nunique'))\n",
    "# df['total_data'] = df['total_data'] / (1_000_000_000 / 8 * 6 * 3600)\n",
    "# df.unstack().plot(kind='bar', y='total_data', rot=0, ax=ax0, color=color)\n",
    "# ax0.set_title('1gbps, 6 hours')\n",
    "# ax0.axhline(1, linestyle='-')\n",
    "# ax0.grid(axis='y')\n",
    "# ax0.set_axisbelow(True)\n",
    "# ax0.legend(loc='lower center', ncol=3)\n",
    "\n",
    "\n",
    "df = logs10g.groupby(['date', 'algorithm'], observed=False).agg(total_data=('size', 'sum'), n_exps=('date', 'nunique'))\n",
    "df['total_data'] = df['total_data'] / (10_000_000_000 / 8 * 4 * 3600)\n",
    "# / (10_000_000_000 / 8 * 3600)\n",
    "df.unstack().plot(kind='bar', y='total_data', rot=0, ax=ax1, color=color)\n",
    "ax1.set_title('10gbps, 4 hours')\n",
    "ax1.axhline(1, linestyle='-')\n",
    "ax1.legend(ncol=2)\n",
    "ax1.grid(axis='y')\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.legend(loc='lower center', ncol=3)\n",
    "\n",
    "fig.suptitle('Goodput divided by the link capacity')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, [ax0, ax1] = plt.subplots(1, 2, figsize=(15, 6), width_ratios=(0.5,1))\n",
    "\n",
    "# df = logs1g[(logs1g['start_at'] > 3600) & (logs1g['start_at'] + logs1g['time'] < 6*3600 - 60)]\n",
    "# df = df[~df['algorithm'].str.contains('pie') | df['date'].str.contains('newpie')]\n",
    "# time_bar_plot(df.groupby(['setup', 'algorithm'], observed=False), ax=ax0)\n",
    "# ax0.set_title('1gbps, 6 hours')\n",
    "# ax0.legend(loc='lower center', ncol=3)\n",
    "# ax0.grid(axis='y')\n",
    "# ax0.set_axisbelow(True)\n",
    "\n",
    "df = logs10g[(logs10g['start_at'] > 1800) & (logs10g['start_at'] + logs10g['time'] < 4*3600 - 6)]\n",
    "df = df[~df['algorithm'].isin(['cake', 'age-cake'])]\n",
    "time_bar_plot(df.groupby(['date', 'algorithm'], observed=False), ax=ax1)\n",
    "ax1.set_title('10gbps, 4 hours')\n",
    "ax1.legend(loc='lower center', ncol=3)\n",
    "ax1.grid(axis='y')\n",
    "ax1.set_axisbelow(True)\n",
    "\n",
    "fig.suptitle('Mean completion time per connection')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs1g[(logs1g['start_at'] > 3600) & (logs1g['start_at'] + logs1g['time'] < 6*3600 - 60)]\n",
    "df = logs10g[(logs10g['start_at'] > 1800) & (logs10g['start_at'] + logs10g['time'] < 4*3600 - 60)]\n",
    "df = df[~df['date'].str.contains('newpie1')]\n",
    "data = df.groupby(['algorithm'], observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem'))\n",
    "# data['interval'] = data['sem_time'] * 1.96 # 95% confidence interval\n",
    "data['color'] = data.index.map(lambda x: mpl.colors.to_hex(mpl.colormaps['tab20'].colors[algo_order.index(x)]).replace('#', '0x'))\n",
    "data['gain'] = data['mean_time'] / data['mean_time'].shift(-1) - 1\n",
    "print(data.to_csv(columns=['mean_time', 'sem_time', 'color', 'gain'], header=False, sep='\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "algonames = ['FIFO', 'CAKE', 'FQ-CoDel', 'CoDel', 'FQ-PIE', 'PIE']\n",
    "algonames = chain.from_iterable((x,x) for x in algonames)\n",
    "algotoname = dict(zip(algo_order, algonames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import batched\n",
    "\n",
    "print('\\\\hline')\n",
    "print('\\\\multirow{2}{*}{Algorithm} & \\multicolumn{2}{c|}{Two-Level version} & \\\\multicolumn{2}{c|}{Base version} & \\\\multirow{2}{*}{Gain} \\\\\\\\')\n",
    "# print('\\\\hline')\n",
    "print(' & {Mean FCT} & {95\\\\% CI} &  {Mean FCT} & {95\\\\% CI} &   \\\\\\\\')\n",
    "print('\\\\hline\\n\\\\hline')\n",
    "for x, y in batched(data.index, 2):\n",
    "    print(\n",
    "        f'{algotoname[x]} & '\n",
    "        f'{data.loc[x, \"mean_time\"]*1000:.4g} & {data.loc[x, \"sem_time\"] * 1.96 *1000:.3g} &'\n",
    "        f'{data.loc[y, \"mean_time\"]*1000:.4g} & {data.loc[y, \"sem_time\"] * 1.96 *1000:.3g} & '\n",
    "        f'{data.loc[x, \"gain\"]*100:.2g} \\\\% \\\\\\\\'\n",
    "    )\n",
    "    print('\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 6332751\n",
    "# df = logs1g[(logs1g['start_at'] > 3600) & (logs1g['start_at'] + logs1g['time'] < 6*3600 - 60)]\n",
    "df = logs10g[(logs10g['start_at'] > 1800) & (logs10g['start_at'] + logs10g['time'] < 4*3600 - 60)]\n",
    "# df = df[~df['algorithm'].str.contains('pie') | df['date'].str.contains('newpie2')]\n",
    "df = df[~df['date'].str.contains('newpie1')]\n",
    "\n",
    "\n",
    "df = df.groupby(['algorithm', 'size'], observed=True).agg(mean_time=('time', 'mean')).unstack('algorithm')\n",
    "\n",
    "print(df.to_csv(sep='\\t', index=True))\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(18, 8))\n",
    "# df.plot(kind='line', y='mean_time', rot=0, ylabel='time (s)', color=color, ax=ax, linewidth=0.5)\n",
    "\n",
    "# ax.axvline(x=threshold, linestyle='--', color='red', alpha=0.5)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "# fig.suptitle('Completion time distribution')\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = [90475270, 6332751, 13746699]\n",
    "# df = logs1g[(logs1g['start_at'] > 3600) & (logs1g['start_at'] + logs1g['time'] < 6*3600 - 60)]\n",
    "\n",
    "# fig, axs = plt.subplots(len(df['date'].cat.categories),1, figsize=(18, 16), sharex=True)\n",
    "# for (date, dfg), ax, thx in zip(df.groupby('date', observed=True), axs, thresholds):\n",
    "#     dfg = dfg.groupby(['algorithm', 'size'], observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem')).unstack('algorithm')\n",
    "#     dfg = dfg.rolling(3, center=True).mean()\n",
    "#     dfg.plot(kind='line', y='mean_time', rot=0, ylabel='time (s)', color=color, ax=ax, linewidth=0.5)\n",
    "\n",
    "#     ax.set_title(date)\n",
    "#     ax.axvline(x=thx, linestyle='--', color='red', alpha=0.5)\n",
    "#     ax.set_xscale('log')\n",
    "#     ax.set_yscale('log')\n",
    "\n",
    "# fig.suptitle('Completion time distribution - no extra delay')\n",
    "# fig.tight_layout()\n",
    "\n",
    "# thresholds = [19500715, 19500715]\n",
    "# df = logs10g[(logs10g['start_at'] > 360) & (logs10g['start_at'] + logs10g['time'] < 4*3600 - 6)]\n",
    "\n",
    "# fig, [axs] = plt.subplots(len(df['date'].cat.categories),1, figsize=(18, 8), sharex=True, squeeze=False)\n",
    "# for (date, dfg), ax, thx in zip(df.groupby('date', observed=True), axs, thresholds):\n",
    "#     dfg = dfg.groupby(['algorithm', 'size'], observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem')).unstack('algorithm')\n",
    "#     dfg = dfg.rolling(3, center=True).mean()\n",
    "#     dfg.plot(kind='line', y='mean_time', rot=0, ylabel='time (s)', color=color, ax=ax, linewidth=0.5)\n",
    "\n",
    "#     ax.set_title(date)\n",
    "#     ax.axvline(x=thx, linestyle='--', color='red', alpha=0.5)\n",
    "#     ax.set_xscale('log')\n",
    "#     ax.set_yscale('log')\n",
    "\n",
    "fig.suptitle('Completion time distribution')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs1g[(logs1g['start_at'] > 3600) & (logs1g['start_at'] + logs1g['time'] < 6*3600 - 60)]\n",
    "df = logs10g\n",
    "bins = [0, 1_000_000, 10_000_000, 90475270, 800_000_000, 6_000_000_000, np.inf]\n",
    "labels = ['<1M', '1M-10M', '10M-90M', '90M-800M', '800M-6G', '6G+']\n",
    "df['size_cat'] = pd.cut(df['size'], bins=bins, labels=labels)\n",
    "\n",
    "df.groupby(['date', 'algorithm', 'size_cat'], observed=True).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "testname_match_antler = re.compile(r'.*/([^/]+)/closedloop_([a-z\\-]+)_procstat-(client|server).json')\n",
    "def load_procstat(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        df = pd.DataFrame(orjson.loads(f.read()))\n",
    "    df['time'] = pd.to_datetime(df['time'], utc=True)\n",
    "    df['time'] = df['time'] - df['time'].min()\n",
    "    df['filename'] = filename\n",
    "    date, algo, node = testname_match_antler.match(filename).groups()\n",
    "    df['date'] = date\n",
    "    df['algorithm'] = pd.Categorical([algo]*len(df), categories=algo_order, ordered=True)\n",
    "    df['node'] = pd.Categorical([node]*len(df), categories=['client', 'server'], ordered=True)\n",
    "    x = df['/proc/stat'].str.split()\n",
    "    df['cpu_user'] = x.str[1].astype(int)\n",
    "    df['cpu_system'] = x.str[3].astype(int)\n",
    "    return df\n",
    "pstats = pd.concat(load_procstat(filename) for filename in glob.glob('../tests/results/6h-*-heavy7/*_procstat-*.json'))\n",
    "pstats.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(4,1, figsize=(15, 25), sharex=True, sharey=True)\n",
    "# for ax, col, node in zip(axs, ['cpu_user', 'cpu_system', 'cpu_user', 'cpu_system'], ['client', 'client', 'server', 'server']):\n",
    "#     for algo, data in pstats[pstats['node'] == node].groupby('algorithm', observed=False):\n",
    "#         df = data.sort_values('time')\n",
    "#         df[['cpu_system', 'cpu_user']] = df[['cpu_system', 'cpu_user']].diff().fillna(0)/100/20\n",
    "#         df['cpu_total'] = df['cpu_user'] + df['cpu_system']\n",
    "#         df.set_index('time', inplace=True)\n",
    "#         # df = df[['cpu_system', 'cpu_user']]\n",
    "#         # df = df[['cpu_system', 'cpu_user']].resample('5min').mean()\n",
    "#         df.plot(y=col, ax=ax, label=algo)\n",
    "#         ax.set_title(f'{node} {col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tot_cpu(series):\n",
    "    return series.max() - series.min()\n",
    "    \n",
    "pstats.groupby(['node', 'algorithm']).agg(cpu_user=('cpu_user', tot_cpu), cpu_system=('cpu_system', tot_cpu)).unstack('node') / (4*3600) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs[(logs['setup'] == setup_renames['long2']) & (logs['seed'] == '15867')]\n",
    "# df = logs1g[logs1g['date'] == '6h-pareto1.2-heavy']\n",
    "df = logs10g#[logs10g['date'] == '4h-10g-2']\n",
    "df['ended_at'] = df['start_at'] + df['time']\n",
    "timepoints = np.linspace(0, df['ended_at'].max(), 200)\n",
    "algos = df['algorithm'].cat.categories\n",
    "partial_means = np.zeros((0, len(algos)))\n",
    "partial_sems = np.zeros((0, len(algos)))\n",
    "\n",
    "for t in timepoints:\n",
    "    # c = df[(df['ended_at'] <= t) & (df['ended_at'] > 3600) & (df['ended_at'] < 6*3600 - 20)]\n",
    "    c = df[df['ended_at'] <= t]\n",
    "    c = c.groupby('algorithm', observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem'))\n",
    "    partial_means = np.vstack([partial_means, c.loc[algos, 'mean_time']])\n",
    "    # partial_sems = np.vstack([partial_sems, c.loc[algos, 'sem_time']])\n",
    "\n",
    "fig, ax = plt.subplots(sharey=True)\n",
    "for i, a in enumerate(algos):\n",
    "    ax.plot(timepoints, partial_means[:, i], label=a, color=color[i])\n",
    "    # lower, upper = partial_means[:, i] - 1.96 * partial_sems[:, i], partial_means[:, i] + 1.96 * partial_sems[:, i]\n",
    "    # ax.fill_between(timepoints, lower, upper, alpha=0.3, color=color[i])\n",
    "    ax.axhline(partial_means[-1, i], linestyle='--', color=color[i], alpha=0.5)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylabel('mean completion time (s)')\n",
    "ax.set_xlabel('elapsed time (s)')\n",
    "ax.set_title('Expanding mean completion time per connection, for runs with the same seed')\n",
    "fig.tight_layout()\n",
    "# df.sort_values('start_at').groupby('algorithm', observed=True)['start_at', 'time'].expanding().mean().unstack().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logs1g[logs1g['date'] == logs1g['date'].cat.categories[1]]\n",
    "df = df[df['actor'] == 33].sort_values('start_at')\n",
    "g = df.groupby(['algorithm'], observed=True)['size'].apply(lambda x: list(x)[18400:18420])\n",
    "pd.DataFrame(dict(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logs1g\n",
    "bins = [0, 1_000_000, 10_000_000, 55000000, 90475270, 500_000_000, 800_000_000, np.inf]\n",
    "labels = ['<1M', '1M-10M', '10M-55M', \"55M-86M\", '86M-500M', '500M-800M', '>800M']\n",
    "df['size_cat'] = pd.cut(df['size'], bins=bins, labels=labels)\n",
    "df = logs1g[logs1g['date'] == logs1g['date'].cat.categories[1]]\n",
    "\n",
    "df = df.groupby(['date', 'algorithm', 'actor'], observed=True).apply(lambda g: g.nsmallest(18000, 'start_at')).reset_index(drop=True)\n",
    "df.groupby(['date', 'algorithm', 'size_cat'], observed=True).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs1g[logs1g['date'] == logs1g['date'].cat.categories[1]]\n",
    "df = logs10g\n",
    "print(len(df['size'].unique()))\n",
    "df['time'].plot(kind='hist', bins=30, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logs1g\n",
    "df['throughput'] = df['size'] / df['time']\n",
    "\n",
    "def fairness_jaine(x):\n",
    "    return np.sum(x) ** 2 / (len(x) * np.sum(x ** 2))\n",
    "\n",
    "df = df.groupby(['date', 'algorithm'], observed=True).agg(fairness=('throughput', fairness_jaine))\n",
    "df.unstack('algorithm').plot(kind='bar', y='fairness', rot=0, ylabel='fairness index', color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logs1g\n",
    "df['throughput'] = df['size'] / df['time']\n",
    "df = df[df['throughput'] > 0]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6), sharey=True, width_ratios=(1,1))\n",
    "for (date, dfd), ax in zip(df.groupby('setup', observed=True), axs):\n",
    "    for (algorithm, dfg), c in zip(dfd.groupby('algorithm', observed=False), color):\n",
    "        dfg = dfg.sort_values('throughput')\n",
    "        lor = dfg['throughput'].cumsum()\n",
    "        lor /= lor.max()\n",
    "        x = np.arange(len(lor)) / len(lor)\n",
    "\n",
    "        idx = np.linspace(0, len(lor) - 1, 100).astype(int)\n",
    "        data = pd.DataFrame({'lorenz': lor.iloc[idx], 'x': x[idx]})\n",
    "\n",
    "        print(data.to_csv(sep='\\t', index=False))\n",
    "\n",
    "        imax = np.argmax(x-lor)\n",
    "        print(x[imax], lor.iloc[imax])\n",
    "\n",
    "        ax.plot(x, lor, label=f'{algorithm}', color=c)\n",
    "        ax.legend(loc='upper left')\n",
    "    ax.set_title(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_curve_gap(x):\n",
    "    x = x.sort_values()\n",
    "    lor = x.cumsum()\n",
    "    lor /= lor.max()\n",
    "    x = np.arange(len(lor)) / len(lor)\n",
    "    return np.max(x - lor)\n",
    "\n",
    "# for df in [logs1g, logs10g]:\n",
    "#     df['throughput'] = df['size'] / df['time']\n",
    "#     df = df[df['throughput'] > 0]\n",
    "\n",
    "#     df = df.groupby(['date', 'algorithm'], observed=True).agg(lorenz_gap=('throughput', lorenz_curve_gap))\n",
    "#     df.unstack('algorithm').plot(kind='bar', y='lorenz_gap', rot=0, ylabel='Lorenz curve gap', color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs1g[(logs1g['start_at'] > 3600) & (logs1g['start_at'] + logs1g['time'] < 6 * 3600 - 60)]\n",
    "df = logs10g[(logs10g['start_at'] > 1800) & (logs10g['start_at'] + logs10g['time'] < 4*3600 - 60)]\n",
    "df = df[~df['date'].str.contains('newpie1')]\n",
    "\n",
    "# df = df[~df['algorithm'].str.contains('pie') | df['date'].str.contains('newpie2')]\n",
    "\n",
    "\n",
    "df['throughput'] = df['size'] / df['time']\n",
    "df = df[df['throughput'] > 0]\n",
    "df = df.groupby('algorithm', observed=True).agg(lorenz_gap=('throughput', lorenz_curve_gap))\n",
    "df['color'] = df.index.map(lambda x: mpl.colors.to_hex(mpl.colormaps['tab20'].colors[algo_order.index(x)]).replace('#', '0x'))\n",
    "print(df.to_csv(sep='\\t', index=True, header=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
