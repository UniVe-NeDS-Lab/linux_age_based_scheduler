{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import csv\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "from plots import color, time_bar_plot, cumulative_traffic_plot\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "plt.rcParams['figure.figsize'] = [15, 6]\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "pd.options.mode.copy_on_write = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = utils.load_antler_df(\n",
    "    # '../tests/results/1gbps/*/*_streams.json*',\n",
    "    # '../tests/results/1gbps/*/*_codel_streams.json*',\n",
    "    '../tests/results/1gbps/6h-pareto1.2-heavy7/*_streams.json*',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = utils.load_antler_df(\n",
    "    # '../tests/results/10gbps/*-2/*_streams.json*',\n",
    "    # '../tests/results/10gbps/*-3/*_streams.json*',\n",
    "    # '../tests/results/10gbps/dead/*_streams.json*',\n",
    "    # '../tests/results/10gbps/newpie1/*pie_streams.json*',\n",
    "    # '../tests/results/10gbps/newpie3/*pie_streams.json*',\n",
    "    # '../tests/results/10gbps/4h-10g-*/*_codel_streams.json*',\n",
    "    # '../tests/results/10gbps/4h-10g-*/*fifo*_streams.json*',\n",
    "    # '../tests/results/10gbps/4h-10g-*/*cake_streams.json*',\n",
    "    '../tests/results/10gbps/*/*_streams.json*',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_order = [\n",
    "    'age-pfifofast',\n",
    "    'pfifo',\n",
    "    'age-cake',\n",
    "    'cake',\n",
    "    'age-prio-fqcodel',\n",
    "    'fqcodel',\n",
    "    'age-prio-codel',\n",
    "    'codel',\n",
    "    'age-prio-fqpie',\n",
    "    'fqpie',\n",
    "    'age-prio-pie',\n",
    "    'pie',\n",
    "]\n",
    "logs['algorithm'] = logs['algorithm'].cat.set_categories(algo_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df = logs\n",
    "\n",
    "df = df.groupby(['date', 'algorithm'], observed=False).agg(total_data=('size', 'sum'), n_exps=('date', 'nunique'))\n",
    "df['total_data'] = df['total_data'] / (1_000_000_000 / 8 * 4 * 3600)\n",
    "\n",
    "# df = logs.groupby(['date', 'algorithm'], observed=False).agg(total_data=('size', 'sum'), n_exps=('date', 'nunique'))\n",
    "# df['total_data'] = df['total_data'] / (10_000_000_000 / 8 * 4 * 3600)\n",
    "\n",
    "df.unstack().plot(kind='bar', y='total_data', rot=0, ax=ax, color=color)\n",
    "ax.set_title('10gbps, 4 hours')\n",
    "ax.axhline(1, linestyle='-')\n",
    "ax.legend(ncol=2)\n",
    "ax.grid(axis='y')\n",
    "ax.set_axisbelow(True)\n",
    "ax.legend(loc='lower center', ncol=3)\n",
    "\n",
    "fig.suptitle('Goodput divided by the link capacity')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# df = logs[(logs['start_at'] > 3600) & (logs['start_at'] + logs['time'] < 6*3600 - 60)] # 1gbps\n",
    "df = logs[(logs['start_at'] > 1800) & (logs['start_at'] + logs['time'] < 4 * 3600 - 6)]  # 10gbps\n",
    "df = df[~df['algorithm'].isin(['cake', 'age-cake'])]\n",
    "df = df[df['time'] > 0]\n",
    "\n",
    "time_bar_plot(df.groupby(['date', 'algorithm'], observed=False), ax=ax)\n",
    "ax.set_title('10gbps, 4 hours')\n",
    "ax.legend(loc='lower center', ncol=3)\n",
    "ax.grid(axis='y')\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "fig.suptitle('Mean completion time per connection')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "algonames = ['FIFO', 'CAKE', 'FQ-CoDel', 'CoDel', 'FQ-PIE', 'PIE']\n",
    "algonames = chain.from_iterable((x,x) for x in algonames)\n",
    "algotoname = dict(zip(algo_order, algonames))\n",
    "\n",
    "def rename_algos(x):\n",
    "    if x.startswith('age-'):\n",
    "        return f'Size-based {algotoname[x]}'\n",
    "    else:\n",
    "        return f'{algotoname[x]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs[(logs['start_at'] > 3600) & (logs['start_at'] + logs['time'] < 6*3600 - 60)]\n",
    "df = logs[(logs['start_at'] > 1800) & (logs['start_at'] + logs['time'] < 4 * 3600 - 60)]\n",
    "data = df.groupby(['algorithm'], observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem'))\n",
    "# data['interval'] = data['sem_time'] * 1.96 # 95% confidence interval\n",
    "data['color'] = data.index.map(lambda x: mpl.colors.to_hex(mpl.colormaps['tab20'].colors[algo_order.index(x)]).replace('#', '0x'))\n",
    "data['gain'] = data['mean_time'] / data['mean_time'].shift(-1) - 1\n",
    "data.index = data.index.map(rename_algos)\n",
    "print(data.to_csv(columns=['mean_time', 'sem_time', 'gain'], header=False, sep='\\t', quoting=csv.QUOTE_NONNUMERIC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import batched\n",
    "\n",
    "print('\\\\hline')\n",
    "print('\\\\multirow{2}{*}{Algorithm} & \\\\multicolumn{2}{c|}{Size-based version} & \\\\multicolumn{2}{c|}{Base version} & \\\\multirow{2}{*}{Gain} \\\\\\\\')\n",
    "# print('\\\\hline')\n",
    "print(' & {Mean FCT} & {95\\\\% CI} &  {Mean FCT} & {95\\\\% CI} &   \\\\\\\\')\n",
    "print('\\\\hline\\n\\\\hline')\n",
    "for x, y in batched(data.index, 2):\n",
    "    print(\n",
    "        f'{x.removeprefix('Size-based ')} & '\n",
    "        f'{data.loc[x, \"mean_time\"]*1000:.4g} & {data.loc[x, \"sem_time\"] * 1.96 *1000:.3g} &'\n",
    "        f'{data.loc[y, \"mean_time\"]*1000:.4g} & {data.loc[y, \"sem_time\"] * 1.96 *1000:.3g} & '\n",
    "        f'{data.loc[x, \"gain\"]*100:.2g} \\\\% \\\\\\\\'\n",
    "    )\n",
    "    print('\\\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 6332751\n",
    "# df = logs[(logs['start_at'] > 3600) & (logs['start_at'] + logs['time'] < 6*3600 - 60)]\n",
    "df = logs[(logs['start_at'] > 1800) & (logs['start_at'] + logs['time'] < 4*3600 - 60)]\n",
    "# df = df[~df['algorithm'].str.contains('pie') | df['date'].str.contains('newpie2')]\n",
    "# df = df[~df['date'].str.contains('newpie1')]\n",
    "\n",
    "\n",
    "df = df.groupby(['algorithm', 'size'], observed=True).agg(mean_time=('time', 'mean')).unstack('algorithm')\n",
    "df.columns = df.columns.map(lambda x: rename_algos(x[1]))\n",
    "\n",
    "print(df.to_csv(sep='\\t', index=True, quoting=csv.QUOTE_NONNUMERIC))\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(18, 8))\n",
    "# df.plot(kind='line', y='mean_time', rot=0, ylabel='time (s)', color=color, ax=ax, linewidth=0.5)\n",
    "\n",
    "# ax.axvline(x=threshold, linestyle='--', color='red', alpha=0.5)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "\n",
    "# fig.suptitle('Completion time distribution')\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = [90475270, 6332751, 13746699]\n",
    "# df = logs[(logs['start_at'] > 3600) & (logs['start_at'] + logs['time'] < 6*3600 - 60)]\n",
    "\n",
    "# fig, axs = plt.subplots(len(df['date'].cat.categories),1, figsize=(18, 16), sharex=True)\n",
    "# for (date, dfg), ax, thx in zip(df.groupby('date', observed=True), axs, thresholds):\n",
    "#     dfg = dfg.groupby(['algorithm', 'size'], observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem')).unstack('algorithm')\n",
    "#     dfg = dfg.rolling(3, center=True).mean()\n",
    "#     dfg.plot(kind='line', y='mean_time', rot=0, ylabel='time (s)', color=color, ax=ax, linewidth=0.5)\n",
    "\n",
    "#     ax.set_title(date)\n",
    "#     ax.axvline(x=thx, linestyle='--', color='red', alpha=0.5)\n",
    "#     ax.set_xscale('log')\n",
    "#     ax.set_yscale('log')\n",
    "\n",
    "# fig.suptitle('Completion time distribution - no extra delay')\n",
    "# fig.tight_layout()\n",
    "\n",
    "# thresholds = [19500715, 19500715]\n",
    "# df = logs[(logs['start_at'] > 360) & (logs['start_at'] + logs['time'] < 4*3600 - 6)]\n",
    "\n",
    "# fig, [axs] = plt.subplots(len(df['date'].cat.categories),1, figsize=(18, 8), sharex=True, squeeze=False)\n",
    "# for (date, dfg), ax, thx in zip(df.groupby('date', observed=True), axs, thresholds):\n",
    "#     dfg = dfg.groupby(['algorithm', 'size'], observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem')).unstack('algorithm')\n",
    "#     dfg = dfg.rolling(3, center=True).mean()\n",
    "#     dfg.plot(kind='line', y='mean_time', rot=0, ylabel='time (s)', color=color, ax=ax, linewidth=0.5)\n",
    "\n",
    "#     ax.set_title(date)\n",
    "#     ax.axvline(x=thx, linestyle='--', color='red', alpha=0.5)\n",
    "#     ax.set_xscale('log')\n",
    "#     ax.set_yscale('log')\n",
    "\n",
    "fig.suptitle('Completion time distribution')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs[(logs['start_at'] > 3600) & (logs['start_at'] + logs['time'] < 6*3600 - 60)]\n",
    "df = logs\n",
    "bins = [0, 1_000_000, 10_000_000, 90475270, 800_000_000, 6_000_000_000, np.inf]\n",
    "labels = ['<1M', '1M-10M', '10M-90M', '90M-800M', '800M-6G', '6G+']\n",
    "df['size_cat'] = pd.cut(df['size'], bins=bins, labels=labels)\n",
    "\n",
    "df.groupby(['date', 'algorithm', 'size_cat'], observed=True).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs[(logs['setup'] == setup_renames['long2']) & (logs['seed'] == '15867')]\n",
    "# df = logs[logs['date'] == '6h-pareto1.2-heavy']\n",
    "df = logs#[logs['date'] == '4h-10g-2']\n",
    "df['ended_at'] = df['start_at'] + df['time']\n",
    "timepoints = np.linspace(0, df['ended_at'].max(), 200)\n",
    "algos = df['algorithm'].cat.categories\n",
    "partial_means = np.zeros((0, len(algos)))\n",
    "partial_sems = np.zeros((0, len(algos)))\n",
    "\n",
    "for t in timepoints:\n",
    "    # c = df[(df['ended_at'] <= t) & (df['ended_at'] > 3600) & (df['ended_at'] < 6*3600 - 20)]\n",
    "    c = df[df['ended_at'] <= t]\n",
    "    c = c.groupby('algorithm', observed=False).agg(mean_time=('time', 'mean'), sem_time=('time', 'sem'))\n",
    "    partial_means = np.vstack([partial_means, c.loc[algos, 'mean_time']])\n",
    "    # partial_sems = np.vstack([partial_sems, c.loc[algos, 'sem_time']])\n",
    "\n",
    "fig, ax = plt.subplots(sharey=True)\n",
    "for i, a in enumerate(algos):\n",
    "    ax.plot(timepoints, partial_means[:, i], label=a, color=color[i])\n",
    "    # lower, upper = partial_means[:, i] - 1.96 * partial_sems[:, i], partial_means[:, i] + 1.96 * partial_sems[:, i]\n",
    "    # ax.fill_between(timepoints, lower, upper, alpha=0.3, color=color[i])\n",
    "    ax.axhline(partial_means[-1, i], linestyle='--', color=color[i], alpha=0.5)\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_ylabel('mean completion time (s)')\n",
    "ax.set_xlabel('elapsed time (s)')\n",
    "ax.set_title('Expanding mean completion time per connection, for runs with the same seed')\n",
    "fig.tight_layout()\n",
    "# df.sort_values('start_at').groupby('algorithm', observed=True)['start_at', 'time'].expanding().mean().unstack().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logs[logs['date'] == logs['date'].cat.categories[1]]\n",
    "df = df[df['actor'] == 33].sort_values('start_at')\n",
    "g = df.groupby(['algorithm'], observed=True)['size'].apply(lambda x: list(x)[18400:18420])\n",
    "pd.DataFrame(dict(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logs\n",
    "bins = [0, 1_000_000, 10_000_000, 55000000, 90475270, 500_000_000, 800_000_000, np.inf]\n",
    "labels = ['<1M', '1M-10M', '10M-55M', \"55M-86M\", '86M-500M', '500M-800M', '>800M']\n",
    "df['size_cat'] = pd.cut(df['size'], bins=bins, labels=labels)\n",
    "df = logs[logs['date'] == logs['date'].cat.categories[1]]\n",
    "\n",
    "df = df.groupby(['date', 'algorithm', 'actor'], observed=True).apply(lambda g: g.nsmallest(18000, 'start_at')).reset_index(drop=True)\n",
    "df.groupby(['date', 'algorithm', 'size_cat'], observed=True).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs[logs['date'] == logs['date'].cat.categories[1]]\n",
    "df = logs\n",
    "print(len(df['size'].unique()))\n",
    "df['time'].plot(kind='hist', bins=30, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logs\n",
    "df['throughput'] = df['size'] / df['time']\n",
    "\n",
    "def fairness_jaine(x):\n",
    "    return np.sum(x) ** 2 / (len(x) * np.sum(x ** 2))\n",
    "\n",
    "df = df.groupby(['date', 'algorithm'], observed=True).agg(fairness=('throughput', fairness_jaine))\n",
    "df.unstack('algorithm').plot(kind='bar', y='fairness', rot=0, ylabel='fairness index', color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = logs\n",
    "df = df[df['time'] > 0]\n",
    "df['throughput'] = df['size'] / df['time']\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, sharey=True, width_ratios=(1,1))\n",
    "# for (date, dfd), ax in zip(df.groupby('setup', observed=True), axs):\n",
    "#     for (algorithm, dfg), c in zip(dfd.groupby('algorithm', observed=False), color):\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "dfg = df[(df['date'] == '4h-new') & (df['algorithm'] == 'age-prio-codel')]\n",
    "dfg = dfg.sort_values('throughput')\n",
    "dfg.hist(bins=100, column='throughput')\n",
    "\n",
    "lor = dfg['throughput'].cumsum()\n",
    "lor /= lor.max()\n",
    "x = np.arange(len(lor)) / len(lor)\n",
    "\n",
    "idx = np.linspace(0, len(lor) - 1, 100).astype(int)\n",
    "# idx = np.arange(len(lor))  # Use all points for the full curve\n",
    "data = pd.DataFrame({'lorenz': lor.iloc[idx], 'x': x[idx]})\n",
    "\n",
    "print(data.to_csv(sep='\\t', index=False))\n",
    "\n",
    "imax = np.argmax(x-lor)\n",
    "# print(x[imax], lor.iloc[imax])\n",
    "\n",
    "ax.plot(x, lor)\n",
    "ax.legend(loc='upper left')\n",
    "# ax.set_title(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_curve_gap(x):\n",
    "    x = x.sort_values()\n",
    "    lor = x.cumsum()\n",
    "    lor /= lor.max()\n",
    "    x = np.arange(len(lor)) / len(lor)\n",
    "    return np.max(x - lor)\n",
    "\n",
    "# for df in [logs, logs]:\n",
    "#     df['throughput'] = df['size'] / df['time']\n",
    "#     df = df[df['throughput'] > 0]\n",
    "\n",
    "#     df = df.groupby(['date', 'algorithm'], observed=True).agg(lorenz_gap=('throughput', lorenz_curve_gap))\n",
    "#     df.unstack('algorithm').plot(kind='bar', y='lorenz_gap', rot=0, ylabel='Lorenz curve gap', color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = logs[(logs['start_at'] > 3600) & (logs['start_at'] + logs['time'] < 6 * 3600 - 60)]\n",
    "df = logs[(logs['start_at'] > 1800) & (logs['start_at'] + logs['time'] < 4*3600 - 60)]\n",
    "# df = df[~df['date'].str.contains('newpie1')]\n",
    "\n",
    "# df = df[~df['algorithm'].str.contains('pie') | df['date'].str.contains('newpie2')]\n",
    "\n",
    "df = df[df['time'] > 0]\n",
    "df['throughput'] = df['size'] / df['time']\n",
    "df = df[df['throughput'] > 0]\n",
    "df = df.groupby(['algorithm'], observed=True).agg(lorenz_gap=('throughput', lorenz_curve_gap))\n",
    "df.index = df.index.map(rename_algos)\n",
    "# df.plot(kind='bar', color=color)\n",
    "print(df.to_csv(sep='\\t', index=True, header=False, quoting=csv.QUOTE_NONNUMERIC))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
